{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c529be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "100%|██████████| 72/72 [00:11<00:00,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1------MSE:102.31681060791016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "gpu_ids = \"1,7\"\n",
    "#     gpu_ids = \"4,5,6,7\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_ids  \n",
    "import pandas as pd\n",
    "from audtorch.metrics.functional import pearsonr\n",
    "from mydata1D import dataGenerator,get_Dataframe_Data\n",
    "from mydata1T import dataGenerator as dataG\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset,ConcatDataset,DataLoader\n",
    "import warnings\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import LambdaLR,CosineAnnealingLR\n",
    "from model.au128 import UNetWithTransformerEncoder\n",
    "import logging  \n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from accelerate import Accelerator\n",
    "from utils.utils_datasetDisease import *\n",
    "import lmdb\n",
    "from noise import UNetn\n",
    "import pytorch_warmup as warmup\n",
    "from model.SQET import SQET\n",
    "\n",
    "\n",
    "\n",
    "class NoiseModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        util_model,\n",
    "        learning_rate=1e-3,\n",
    "        noise_coeff=15,\n",
    "        min_scale=0,\n",
    "        max_scale=1,\n",
    "        batch_size=16,\n",
    "        pretrained=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.util_model = util_model\n",
    "        # for layer in self.util_model.layers:\n",
    "        #     layer.trainable = False\n",
    "        for param in self.util_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.noise_model = UNetn()\n",
    "\n",
    "\n",
    "        self.normal = torch.distributions.normal.Normal(0, 1)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.min_scale = min_scale\n",
    "        self.max_scale = max_scale\n",
    "        self.noise_coeff = noise_coeff\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        B = torch.sigmoid(self.noise_model(x))\n",
    "\n",
    "        # sample from normal  distribution\n",
    "#         epsilon = self.normal.sample(B.shape).type_as(B)\n",
    "\n",
    "        # reparametiation trick\n",
    "        # print('B',torch.mean(B),torch.max(B),torch.min(B))\n",
    "        # print('epsilon',torch.mean(epsilon),torch.max(epsilon),torch.min(epsilon))\n",
    "        noise = B * 10\n",
    "        age_pred = self.util_model((x + noise).float()).squeeze()\n",
    "\n",
    "        return B,noise,age_pred\n",
    "\n",
    "def train(model,criterion,L1,optimizer,train_loader,epoch,epochs,lr,k,scheduler,warmup_scheduler,device):\n",
    "    model.train()\n",
    "    Loss = 0\n",
    "    BS = 0\n",
    "    MSE = 0\n",
    "    bloss = 10000  \n",
    "    with torch.no_grad():\n",
    "        for imgs,age in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            imgs, age = imgs.to(device), age.to(device)\n",
    "            age_pred = model(imgs)['final']\n",
    "\n",
    "\n",
    "            mse = criterion(age_pred.float(), age.float())\n",
    "            MSE += mse.data\n",
    "\n",
    "\n",
    "    #         print(f'loss:{loss}-----mse:{mse}---------bs:{bs}')\n",
    "\n",
    "        MSE = MSE / len(train_loader)\n",
    "        print(f'{epoch}/{epochs}------MSE:{MSE}')\n",
    "#     if Loss < bloss:\n",
    "#         torch.save(model.module.state_dict(), f\"unoise{k}.pth\")\n",
    "#             torch.save(model.state_dict(),'net_params.pth.')\n",
    "#         torch.save(model.state_dict(), f\"unoise{k}.pth\")\n",
    "        \n",
    "    with warmup_scheduler.dampening():\n",
    "        if epoch < 10:\n",
    "            pass\n",
    "        else:\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "\n",
    "def main(dataframe_paths, env, batch_size, epochs,k):\n",
    "    accelerator = Accelerator(split_batches=True)\n",
    "\n",
    "    # 数据准备\n",
    "\n",
    "    \n",
    "    # 实例化dataGenerator\n",
    "    # train_dataset = dataGenerator(train_IXI, lmdb_path)\n",
    "    # val_dataset = dataGenerator(val_IXI, lmdb_path)\n",
    "    train_dataset = my_dataset(dataframe_paths[0], env, True, 0)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=0, pin_memory=True,drop_last=True)    # nw 一般为0\n",
    "\n",
    "\n",
    "    # train_dataset = dataGenerator(train_IXI, lmdb_path)\n",
    "    # val_dataset = dataGenerator(val_IXI, lmdb_path)\n",
    "\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=0, pin_memory=True,drop_last=True)\n",
    "    # val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=0, pin_memory=True,drop_last=True)\n",
    "    # 模型配置\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    dict = {'dim': (128, 256, 512),\n",
    "            'depth':(2, 8, 2),\n",
    "            'global_window_size': (8, 4, 2),\n",
    "            'use_se': True,\n",
    "            'use_pse': False,\n",
    "            'use_sequence_pooling': True,\n",
    "            'input_shape': [128, 128, 128]\n",
    "            }\n",
    "\n",
    "\n",
    "    # TODO:实例化模型\n",
    "    model = SQET(\n",
    "        dim=dict['dim'],  # dimension at each stage\n",
    "        depth=dict['depth'],  # depth of transformer at each stage\n",
    "        global_window_size=dict['global_window_size'],  # global window sizes at each stage\n",
    "        use_se=dict['use_se'],\n",
    "        use_pse=dict['use_pse'],\n",
    "        use_sequence_pooling=dict['use_sequence_pooling'],\n",
    "        input_shape=dict['input_shape'],\n",
    "        attn_dropout=0.,\n",
    "        ff_dropout=0.3\n",
    "    ).to(device)\n",
    "    model_path = \"./results_checkpoint/SQET/checkpoint_best.tar\"\n",
    "    \n",
    "#     util_model = UNetWithTransformerEncoder(32, 8, 6, 128, 0.1).to(device)\n",
    "    checkpoint1 = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint1['model_state_dict'], strict=False)\n",
    "#     model_path = \"./results_checkpoint/Unet/checkpoint_best.tar\"\n",
    "\n",
    "#     model = UNetWithTransformerEncoder(32, 8, 6, 128, 0.1).to(device)\n",
    "#     checkpoint1 = torch.load(model_path)\n",
    "#     model.load_state_dict(checkpoint1['model_state_dict'], strict=False)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-2, weight_decay=1e-2)\n",
    "    \n",
    "    # optimizer = torch.optim.SGD(params=model.parameters(),lr = 0.00001, momentum=0.5)\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=2, verbose=False, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=1e-8, eps=1e-08)\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=2, verbose=False, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=1e-6, eps=1e-08)\n",
    "    scheduler =  CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-5)\n",
    "    # scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=100, T_mult=2, eta_min=7e-6)\n",
    "    # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "    #     optimizer = torch.optim.AdamW(model.parameters(), lr=args.learning_rate,\n",
    "    #                                   weight_decay=args.weight_decay)\n",
    "    #     # TODO 学习率\n",
    "    #     scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=500, T_mult=2, eta_min=2e-5)\n",
    "    #     # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "    warmup_scheduler = warmup.LinearWarmup(optimizer, warmup_period=4)\n",
    "    # accelerator.print('training...')\n",
    "    criterion = nn.MSELoss()\n",
    "    L1 = nn.L1Loss()\n",
    "    \n",
    "    # 训练循环\n",
    "    for epoch in range(epochs):\n",
    "        # ... 训练和验证过程 ...\n",
    "        # 记录日志、保存模型等\n",
    "        lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "        train(model,criterion,L1,optimizer,train_loader,epoch,epochs,lr,k,scheduler,warmup_scheduler,device)\n",
    "        \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    \n",
    "    k = 'SZ'\n",
    "    dataframe_paths = [f'csvs/{k}.csv', f'csvs/{k}.csv']\n",
    "    # dataframe_paths = ['5-fold/train_2.csv', '5-fold/val_2.csv']\n",
    "    batch_size = 1\n",
    "    epochs = 1\n",
    "    env = lmdb.open(\"/home/caojiaxiang/disease_data\", readonly=True, lock=False, readahead=False,\n",
    "                        meminit=False)\n",
    "    main(dataframe_paths, env, batch_size, epochs,k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa5d1962-0091-403c-a68a-71094bd87e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caojiaxiang/.local/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(split_batches=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "  0%|          | 0/72 [00:00<?, ?it/s]/home/user/anaconda3/envs/torch112/lib/python3.9/site-packages/torch/_tensor.py:1121: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  ret = func(*args, **kwargs)\n",
      "100%|██████████| 72/72 [00:39<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/200-------Loss:295.7616882324219----BS:-0.8573681116104126----MSE:154.72476196289062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:32<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/200-------Loss:208.47500610351562----BS:-0.8367462158203125----MSE:97.7495346069336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/200-------Loss:272.3033142089844----BS:-0.794295608997345----MSE:142.5313720703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/200-------Loss:298.59552001953125----BS:-0.7611318826675415----MSE:162.9511260986328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/200-------Loss:219.5318603515625----BS:-0.7569014430046082----MSE:111.18446350097656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/200-------Loss:151.51113891601562----BS:-0.7153610587120056----MSE:67.63530731201172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/200-------Loss:125.76615142822266----BS:-0.6699857115745544----MSE:52.5391960144043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/200-------Loss:105.5341796875----BS:-0.6404867768287659----MSE:40.44851303100586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/200-------Loss:82.35935974121094----BS:-0.6094357371330261----MSE:26.436569213867188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/200-------Loss:63.21118927001953----BS:-0.5811030268669128----MSE:14.870614051818848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/200-------Loss:74.00394439697266----BS:-0.5506337881088257----MSE:23.55191993713379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/200-------Loss:67.7399673461914----BS:-0.5409255623817444----MSE:19.80045509338379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/200-------Loss:67.65064239501953----BS:-0.5140187740325928----MSE:20.936927795410156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/200-------Loss:61.48275375366211----BS:-0.49984583258628845----MSE:17.430936813354492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/200-------Loss:59.0590705871582----BS:-0.47946134209632874----MSE:16.733867645263672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/200-------Loss:60.38368606567383----BS:-0.46166977286338806----MSE:18.452743530273438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/200-------Loss:46.3214111328125----BS:-0.4322388470172882----MSE:10.416333198547363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/200-------Loss:41.06838607788086----BS:-0.4093448519706726----MSE:7.997816562652588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/200-------Loss:35.55615997314453----BS:-0.3866596519947052----MSE:5.409740924835205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/200-------Loss:34.561180114746094----BS:-0.36274051666259766----MSE:5.8009514808654785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/200-------Loss:33.03429412841797----BS:-0.3413909375667572----MSE:5.770875930786133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/200-------Loss:32.35728454589844----BS:-0.31872689723968506----MSE:6.35360050201416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/200-------Loss:36.14576721191406----BS:-0.3063472807407379----MSE:9.439452171325684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/200-------Loss:40.0413703918457----BS:-0.2871796488761902----MSE:13.008686065673828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/200-------Loss:30.12384033203125----BS:-0.2754049301147461----MSE:6.943163871765137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/200-------Loss:28.065881729125977----BS:-0.2618549168109894----MSE:6.196703910827637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/200-------Loss:31.755889892578125----BS:-0.2499004751443863----MSE:9.21010684967041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/200-------Loss:28.75111961364746----BS:-0.23832488059997559----MSE:7.7594146728515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/200-------Loss:25.08924102783203----BS:-0.22598235309123993----MSE:5.897013187408447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/200-------Loss:23.724843978881836----BS:-0.21146471798419952----MSE:5.663022994995117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/200-------Loss:24.696657180786133----BS:-0.20093758404254913----MSE:6.820357799530029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/200-------Loss:24.508968353271484----BS:-0.18981964886188507----MSE:7.2150444984436035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/200-------Loss:19.210006713867188----BS:-0.1823180764913559----MSE:4.050852298736572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/200-------Loss:17.7780704498291----BS:-0.1711208075284958----MSE:3.628092050552368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/200-------Loss:14.852238655090332----BS:-0.16496486961841583----MSE:1.9834572076797485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/200-------Loss:14.408146858215332----BS:-0.1545296162366867----MSE:2.1759884357452393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/200-------Loss:13.93306827545166----BS:-0.14693784713745117----MSE:2.218299627304077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/200-------Loss:12.671856880187988----BS:-0.14097140729427338----MSE:1.6731027364730835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/200-------Loss:12.396400451660156----BS:-0.13497261703014374----MSE:1.7739055156707764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 65/72 [00:30<00:03,  2.12it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 186\u001b[0m\n\u001b[1;32m    183\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[1;32m    184\u001b[0m env \u001b[38;5;241m=\u001b[39m lmdb\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/caojiaxiang/disease_data\u001b[39m\u001b[38;5;124m\"\u001b[39m, readonly\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, readahead\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    185\u001b[0m                     meminit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 186\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 170\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(dataframe_paths, env, batch_size, epochs, k)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# ... 训练和验证过程 ...\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# 记录日志、保存模型等\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     lr \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstate_dict()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_groups\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 170\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mL1\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwarmup_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 99\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, criterion, L1, optimizer, train_loader, epoch, epochs, lr, k, scheduler, warmup_scheduler, device)\u001b[0m\n\u001b[1;32m     96\u001b[0m         MSE \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m mse\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m     98\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 99\u001b[0m         \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m#         print(f'loss:{loss}-----mse:{mse}---------bs:{bs}')\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     Loss \u001b[38;5;241m=\u001b[39m Loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "File \u001b[0;32m/home/user/anaconda3/envs/torch112/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:65\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     64\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/user/anaconda3/envs/torch112/lib/python3.9/site-packages/torch/optim/optimizer.py:109\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/user/anaconda3/envs/torch112/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/user/anaconda3/envs/torch112/lib/python3.9/site-packages/torch/optim/adamw.py:161\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    157\u001b[0m             max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    159\u001b[0m         state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 161\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m          \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m          \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m          \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m          \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m          \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m          \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m          \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m          \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m          \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/home/user/anaconda3/envs/torch112/lib/python3.9/site-packages/torch/optim/adamw.py:218\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 218\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/user/anaconda3/envs/torch112/lib/python3.9/site-packages/torch/optim/adamw.py:269\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    268\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mmul_(beta1)\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m--> 269\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable:\n\u001b[1;32m    272\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#SZ\n",
    "import os\n",
    "gpu_ids = \"1,7\"\n",
    "#     gpu_ids = \"4,5,6,7\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_ids  \n",
    "import pandas as pd\n",
    "from audtorch.metrics.functional import pearsonr\n",
    "from mydata1D import dataGenerator,get_Dataframe_Data\n",
    "from mydata1T import dataGenerator as dataG\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset,ConcatDataset,DataLoader\n",
    "import warnings\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import LambdaLR,CosineAnnealingLR\n",
    "from model.au128 import UNetWithTransformerEncoder\n",
    "import logging  \n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from accelerate import Accelerator\n",
    "from utils.utils_datasetDisease import *\n",
    "import lmdb\n",
    "from noise import UNetn\n",
    "import pytorch_warmup as warmup\n",
    "from model.SQET import SQET\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "\n",
    "class NoiseModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        util_model,\n",
    "        learning_rate=1e-3,\n",
    "        noise_coeff=15,\n",
    "        min_scale=0,\n",
    "        max_scale=1,\n",
    "        batch_size=16,\n",
    "        pretrained=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.util_model = util_model\n",
    "        # for layer in self.util_model.layers:\n",
    "        #     layer.trainable = False\n",
    "        for param in self.util_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.noise_model = UNetn()\n",
    "\n",
    "\n",
    "        self.normal = torch.distributions.normal.Normal(0, 1)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.min_scale = min_scale\n",
    "        self.max_scale = max_scale\n",
    "        self.noise_coeff = noise_coeff\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        B = torch.sigmoid(self.noise_model(x))\n",
    "\n",
    "        # sample from normal  distribution\n",
    "#         epsilon = self.normal.sample(B.shape).type_as(B)\n",
    "\n",
    "        # reparametiation trick\n",
    "        # print('B',torch.mean(B),torch.max(B),torch.min(B))\n",
    "        # print('epsilon',torch.mean(epsilon),torch.max(epsilon),torch.min(epsilon))\n",
    "        noise = B * 10\n",
    "        age_pred = self.util_model((x + noise).float()).squeeze()\n",
    "\n",
    "        return B,noise,age_pred\n",
    "\n",
    "def train(model,criterion,L1,optimizer,train_loader,epoch,epochs,lr,k,scheduler,warmup_scheduler,device):\n",
    "    model.train()\n",
    "    Loss = 0\n",
    "    BS = 0\n",
    "    MSE = 0\n",
    "    bloss = 10000    \n",
    "    for imgs,age in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        imgs, age = imgs.to(device), age.to(device)\n",
    "        B,noise,age_pred = model(imgs)\n",
    "        bs = torch.mean(B.log())\n",
    "        \n",
    "        mse = criterion(age_pred.float(), age.float())\n",
    "        loss =  mse * 1.5 - torch.var(B) * 10 ** 2 - 75 * bs\n",
    "        Loss += loss.data\n",
    "        BS += bs.data\n",
    "        MSE += mse.data\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         print(f'loss:{loss}-----mse:{mse}---------bs:{bs}')\n",
    "    Loss = Loss / len(train_loader)\n",
    "    BS = BS / len(train_loader)\n",
    "    MSE = MSE / len(train_loader)\n",
    "    print(f'{epoch}/{epochs}-------Loss:{Loss}----BS:{BS}----MSE:{MSE}')\n",
    "    if Loss < bloss:\n",
    "#         torch.save(model.module.state_dict(), f\"unoise{k}.pth\")\n",
    "#             torch.save(model.state_dict(),'net_params.pth.')\n",
    "        torch.save(model.state_dict(), f\"unoise{k}.pth\")\n",
    "        \n",
    "    with warmup_scheduler.dampening():\n",
    "        if epoch < 10:\n",
    "            pass\n",
    "        else:\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "\n",
    "def main(dataframe_paths, env, batch_size, epochs,k):\n",
    "    accelerator = Accelerator(split_batches=True)\n",
    "\n",
    "    # 数据准备\n",
    "\n",
    "    \n",
    "    # 实例化dataGenerator\n",
    "    # train_dataset = dataGenerator(train_IXI, lmdb_path)\n",
    "    # val_dataset = dataGenerator(val_IXI, lmdb_path)\n",
    "    train_dataset = my_dataset(dataframe_paths[0], env, True, 0)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=0, pin_memory=True,drop_last=True)    # nw 一般为0\n",
    "\n",
    "\n",
    "    # train_dataset = dataGenerator(train_IXI, lmdb_path)\n",
    "    # val_dataset = dataGenerator(val_IXI, lmdb_path)\n",
    "\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=0, pin_memory=True,drop_last=True)\n",
    "    # val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=0, pin_memory=True,drop_last=True)\n",
    "    # 模型配置\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model_path = \"./results_checkpoint/Unet/checkpoint_best.tar\"\n",
    "    \n",
    "    util_model = UNetWithTransformerEncoder(32, 8, 6, 128, 0.1).to(device)\n",
    "    checkpoint1 = torch.load(model_path)\n",
    "    util_model.load_state_dict(checkpoint1['model_state_dict'], strict=False)\n",
    "    model = NoiseModel(util_model).to(device)\n",
    "#     model = nn.DataParallel(model).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "    \n",
    "    # optimizer = torch.optim.SGD(params=model.parameters(),lr = 0.00001, momentum=0.5)\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=2, verbose=False, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=1e-8, eps=1e-08)\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=2, verbose=False, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=1e-6, eps=1e-08)\n",
    "    scheduler =  CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-5)\n",
    "    # scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=100, T_mult=2, eta_min=7e-6)\n",
    "    # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "    #     optimizer = torch.optim.AdamW(model.parameters(), lr=args.learning_rate,\n",
    "    #                                   weight_decay=args.weight_decay)\n",
    "    #     # TODO 学习率\n",
    "    #     scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=500, T_mult=2, eta_min=2e-5)\n",
    "    #     # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "    warmup_scheduler = warmup.LinearWarmup(optimizer, warmup_period=4)\n",
    "    # accelerator.print('training...')\n",
    "    criterion = nn.MSELoss()\n",
    "    L1 = nn.L1Loss()\n",
    "    \n",
    "    # 训练循环\n",
    "    for epoch in range(epochs):\n",
    "        # ... 训练和验证过程 ...\n",
    "        # 记录日志、保存模型等\n",
    "        lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "        train(model,criterion,L1,optimizer,train_loader,epoch,epochs,lr,k,scheduler,warmup_scheduler,device)\n",
    "        \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    \n",
    "    k = 'SZ'\n",
    "    dataframe_paths = [f'csvs/{k}.csv', f'csvs/{k}.csv']\n",
    "    # dataframe_paths = ['5-fold/train_2.csv', '5-fold/val_2.csv']\n",
    "    batch_size = 1\n",
    "    epochs = 200\n",
    "    env = lmdb.open(\"/home/caojiaxiang/disease_data\", readonly=True, lock=False, readahead=False,\n",
    "                        meminit=False)\n",
    "    main(dataframe_paths, env, batch_size, epochs,k)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
